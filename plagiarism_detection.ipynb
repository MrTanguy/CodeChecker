{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['var x = math.floor(math.random() * 5);\\nb = 2\\n\\nvar kek = \"kek\";\\n\\nif(x==1) {\\n    b = 3\\n} else {\\n    b = 1\\n}\\n\\n\\n// DDDDDDDDDDDDdd\\n/* HEHEBOY \\n\\n\\n\\nSDqsd\\n*/', 'Content3\\n\\n// Normal Commentary', 'yes\\n// LE CHOCOLAT\\n// SQDJQSDIQSDISDISDISJDISQOQIDQSOIDQSIDJQSIDJSIOJDISQDJIOSQDOIQSDJIQSDOQSJD0IQSDOKSDOIQSJODQSJDOQKDJs', 'HEHE']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from numpy import vectorize \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import plotly.graph_objects as go\n",
    "import string\n",
    "\n",
    "s=\"\"\n",
    "sample_files = []\n",
    "load_dotenv()\n",
    "\n",
    "Space_Cleared_Exts = os.environ[\"EXTENSIONS\"].replace(\" \", \"\")\n",
    "# ------------------------------------------------------------------\n",
    "# Parcourt tout les fichiers finissant avec les extensions dans .env\n",
    "# ------------------------------------------------------------------\n",
    "for ext in os.environ[\"EXTENSIONS\"] :\n",
    "    if(ext==\",\") :\n",
    "        ext=\"[\"\n",
    "        for doc in os.listdir(\"./FilesToTest/\") :\n",
    "            if doc.endswith(str(s)) :\n",
    "                sample_files.append(''.join(doc))\n",
    "        s = \"\"\n",
    "    if(ext!=\"[\" and ext!=\"]\") :\n",
    "        s+=ext\n",
    "for doc in os.listdir(\"./FilesToTest/\") :\n",
    "    if doc.endswith(str(s.replace(\" \",\"\"))) :\n",
    "        sample_files.append(''.join(doc))\n",
    " \n",
    "sample_contents = [open(\"./FilesToTest/\"+File).read() for File in sample_files]\n",
    "print(sample_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "Commentary_Content = []\n",
    "Var_Content = []\n",
    "Equal_Content = []\n",
    "Sample_Content_Double = []\n",
    "Sample_Content_Without_VarComms = []\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# Parcourt notre texte et enleve les commentaires si le texte vient d'un fichier JS\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "def PurgeJSCommentary(word) :\n",
    "    Sample_ContentsBis = sample_contents[word].splitlines(True)\n",
    "    Sample_Content_SubFile = []\n",
    "    Commentary_SubFile = []\n",
    "    Long_Comment = False\n",
    "    for lines in Sample_ContentsBis :\n",
    "        if(Long_Comment) :\n",
    "            Commentary_SubFile.append(lines)\n",
    "        if(\"//\" in lines) :\n",
    "            Commentary_SubFile.append(lines)\n",
    "        if(\"/*\" in lines):\n",
    "            Long_Comment = True\n",
    "            Commentary_SubFile.append(lines)\n",
    "        if(\"*/\" in lines):\n",
    "            Long_Comment = False\n",
    "            Commentary_SubFile.append(lines)\n",
    "        else :\n",
    "            Sample_Content_SubFile.append(lines)\n",
    "    Sample_Content_Double.append(Sample_Content_SubFile)\n",
    "    Commentary_Content.append(Commentary_SubFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PurgeJSVariables(index) :\n",
    "    Sample_Content_SubFile = []\n",
    "    Var_SubFile = []\n",
    "    for lines in Sample_Content_Double[index] :\n",
    "        if(\"var\" in lines) :\n",
    "            Var_SubFile.append(lines)\n",
    "        else :\n",
    "            Sample_Content_SubFile.append(lines)\n",
    "    Sample_Content_Without_VarComms.append(Sample_Content_SubFile)\n",
    "    Var_Content.append(Var_SubFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PurgeJSEquals(index) :\n",
    "    Sample_Content_SubFile =[]\n",
    "    Equal_SubFile = []\n",
    "    for lines in Sample_Content_Without_VarComms[index] :\n",
    "        if(\"=\" in lines) :\n",
    "            Equal_SubFile.append(lines)\n",
    "        else :\n",
    "            Sample_Content_SubFile.append(lines)\n",
    "    Sample\n",
    "    Equal_Content.append(Equal_SubFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SwitchArray() :\n",
    "    sample_contents = Sample_Content_Double\n",
    "    Sample_Content_Double.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i in range(len(sample_files)) :\n",
    "        if(sample_files[i].endswith(\".js\")) :\n",
    "            PurgeJSCommentary(i)\n",
    "            PurgeJSVariables(i)\n",
    "            # PurgeJSEquals(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['// DDDDDDDDDDDDdd\\n', '/* HEHEBOY \\n', '\\n', '\\n', '\\n', 'SDqsd\\n', '*/', '*/'], ['// Normal Commentary'], ['// LE CHOCOLAT\\n', '// SQDJQSDIQSDISDISDISJDISQOQIDQSOIDQSIDJQSIDJSIOJDISQDJIOSQDOIQSDJIQSDOQSJD0IQSDOKSDOIQSJODQSJDOQKDJs']]\n",
      "[['b = 2\\n', '\\n', '\\n', 'if(x==1) {\\n', '    b = 3\\n', '} else {\\n', '    b = 1\\n', '}\\n', '\\n', '\\n', '// DDDDDDDDDDDDdd\\n', '/* HEHEBOY \\n', '\\n', '\\n', '\\n', 'SDqsd\\n'], ['Content3\\n', '\\n', '// Normal Commentary'], ['yes\\n', '// LE CHOCOLAT\\n', '// SQDJQSDIQSDISDISDISJDISQOQIDQSOIDQSIDJQSIDJSIOJDISQDJIOSQDOIQSDJIQSDOQSJD0IQSDOKSDOIQSJODQSJDOQKDJs']]\n",
      "[['var x = math.floor(math.random() * 5);\\n', 'var kek = \"kek\";\\n'], [], []]\n"
     ]
    }
   ],
   "source": [
    "print(Commentary_Content)\n",
    "print(Sample_Content_Without_VarComms)\n",
    "print(Var_Content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize() :\n",
    "    return \"\"\n",
    "tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var': 12, 'math': 9, 'floor': 4, 'random': 10, 'kek': 7, 'if': 6, 'else': 3, 'dddddddddddddd': 2, 'heheboy': 5, 'sdqsd': 11, 'content3': 1, 'yes': 13, 'le': 8, 'chocolat': 0}\n"
     ]
    }
   ],
   "source": [
    "# vectorize = lambda Text: TfidfVectorizer().fit_transform(Text).toarray()\n",
    "\n",
    "x = TfidfVectorizer()\n",
    "x.fit_transform(Sample_ContentsBis)\n",
    "print(x.vocabulary_)\n",
    "def vectorize(Text) :\n",
    "    return TfidfVectorizer().fit_transform(Text).toarray()\n",
    "\n",
    "# similarity = lambda doc1, doc2: cosine_similarity([doc1, doc2])\n",
    "\n",
    "def similarity(doc1,doc2) :\n",
    "    return cosine_similarity([doc1,doc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectors = vectorize(Sample_ContentsBis)\n",
    "s_vectors = list(zip(sample_files, vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_plagiarism():\n",
    "    results = set()\n",
    "    global s_vectors\n",
    "    for sample_a, text_vector_a in s_vectors:\n",
    "        new_vectors = s_vectors.copy()\n",
    "        current_index = new_vectors.index((sample_a, text_vector_a))\n",
    "        del new_vectors[current_index]\n",
    "        for sample_b, text_vector_b in new_vectors:\n",
    "            sim_score = similarity(text_vector_a, text_vector_b)[0][1]\n",
    "            sample_pair = sorted((sample_a, sample_b))\n",
    "            score = sample_pair[0], sample_pair[1], sim_score\n",
    "            results.add(score)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('no.js', 'testingfile.js', 0.0)\n",
      "('carabistouille.c', 'no.js', 0.13675697456974828)\n",
      "('carabistouille.c', 'yes.js', 0.0)\n",
      "('testingfile.js', 'yes.js', 0.0)\n",
      "('no.js', 'yes.js', 0.0)\n",
      "('carabistouille.c', 'testingfile.js', 0.0)\n"
     ]
    }
   ],
   "source": [
    "for data in check_plagiarism():\n",
    "    print(data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
