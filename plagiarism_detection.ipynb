{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Python\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from numpy import vectorize \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from sty import fg\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# import fichier\n",
    "from Functions import json_decoder as jsd\n",
    "\n",
    "# Mise en place de l'environnement de travail \n",
    "# - Récupération de l'extension souhaitée \n",
    "# - Tri des fichiers à analyser\n",
    "s=\"\"\n",
    "sample_files = []\n",
    "load_dotenv()\n",
    "Space_Cleared_Exts = os.environ[\"EXTENSIONS\"].replace(\" \", \"\")\n",
    "\n",
    "for ext in os.environ[\"EXTENSIONS\"] :\n",
    "    if(ext==\",\") :\n",
    "        ext=\"[\"\n",
    "        for doc in os.listdir(\"./FilesToTest/\") :\n",
    "            if doc.endswith(str(s)) :\n",
    "                sample_files.append(''.join(doc))\n",
    "        s = \"\"\n",
    "    if(ext!=\"[\" and ext!=\"]\") :\n",
    "        s+=ext\n",
    "for doc in os.listdir(\"./FilesToTest/\") :\n",
    "    if doc.endswith(str(s.replace(\" \",\"\"))) :\n",
    "        sample_files.append(''.join(doc))\n",
    "\n",
    "# sample_contents contient tous les codes de tous les fichiers .py\n",
    "sample_contents = [open(\"./FilesToTest/\"+File).read() for File in sample_files]\n",
    "\n",
    "\n",
    "if (len(sample_contents) <= 1):\n",
    "    sys.exit(\"Vous devez mettre un dossier avec un minimum 2 fichiers Python\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Commentary_Content = []\n",
    "Var_Content = []\n",
    "Equal_Content = []\n",
    "Loop_Content = []\n",
    "\n",
    "Sample_Content_Double = []\n",
    "Sample_Content_Without_CommsLoops = []\n",
    "Sample_Content_Without_CommsLoopsVar = []\n",
    "# ---------------------------------------------------------------------------------\n",
    "# Parcourt notre texte et enleve les commentaires si le texte vient d'un fichier JS\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "# PurgeCommentary\n",
    "#  \n",
    "def PurgeCommentary(com_format,ext_com_format, syntax) :\n",
    "    Sample_ContentsBis = sample_contents[syntax].splitlines(True)\n",
    "    Sample_Content_SubFile = []\n",
    "    Commentary_SubFile = []\n",
    "    Long_Comment = False\n",
    "    Append_Lines = False    \n",
    "    Stop_Ext_Com = \"None\"\n",
    "    for lines in Sample_ContentsBis :\n",
    "        #print(lines)\n",
    "        for syntax in com_format :\n",
    "            for ext in ext_com_format :\n",
    "                if(Stop_Ext_Com in lines):\n",
    "                    Long_Comment = False\n",
    "                    Append_Lines = True\n",
    "                if(Long_Comment) :\n",
    "                    Append_Lines = True\n",
    "                if(syntax in lines) :\n",
    "                    Append_Lines = True\n",
    "                if(ext in lines):\n",
    "                    Append_Lines = True\n",
    "                    Long_Comment = True\n",
    "                    if(ext==\"/*\") :\n",
    "                        Stop_Ext_Com = \"*/\"\n",
    "        if(Append_Lines == False and Stop_Ext_Com not in lines and Long_Comment == False):\n",
    "            Sample_Content_SubFile.append(lines)\n",
    "        if(Append_Lines and Long_Comment == False) :\n",
    "            Commentary_SubFile.append(lines)\n",
    "            Append_Lines = False\n",
    "        elif(Append_Lines and Long_Comment) :\n",
    "            Commentary_SubFile.append(lines)\n",
    "    Sample_Content_Double.append(Sample_Content_SubFile)\n",
    "    Commentary_Content.append(Commentary_SubFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PurgeLoops(format, index) :\n",
    "    Sample_Content_SubFile = []\n",
    "    Loop_SubFile = []\n",
    "    IsLoop = False\n",
    "    Append_Lines = False\n",
    "    Stop_Loop_Text = \"None\"\n",
    "    for lines in Sample_Content_Double[index] :\n",
    "        for syntax in format :\n",
    "            if(Stop_Loop_Text in lines):\n",
    "                Append_Lines = True\n",
    "                IsLoop = False\n",
    "            if(IsLoop) :\n",
    "                Append_Lines = True\n",
    "            if(syntax in lines) :\n",
    "                Append_Lines = True\n",
    "                IsLoop = True\n",
    "                if(syntax==\"{\") :\n",
    "                    Stop_Loop_Text = \"}\"\n",
    "        if(Append_Lines == False and Stop_Loop_Text not in lines and IsLoop == False):\n",
    "            Sample_Content_SubFile.append(lines) \n",
    "        if(Append_Lines and IsLoop == False) : \n",
    "            Loop_SubFile.append(lines)\n",
    "            Append_Lines = False\n",
    "        elif(Append_Lines and IsLoop) :\n",
    "            Loop_SubFile.append(lines)\n",
    "    Sample_Content_Without_CommsLoops.append(Sample_Content_SubFile)\n",
    "    Loop_Content.append(Loop_SubFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PurgeVariables(format, index) :\n",
    "    Sample_Content_SubFile = []\n",
    "    Var_SubFile = []\n",
    "    Append_Lines = False\n",
    "    for lines in Sample_Content_Without_CommsLoops[index] :\n",
    "        for syntax in format : \n",
    "            if(syntax in lines) :\n",
    "                Append_Lines = True\n",
    "        if(Append_Lines) :\n",
    "            Var_SubFile.append(lines)\n",
    "            Append_Lines = False\n",
    "        else :\n",
    "                Sample_Content_SubFile.append(lines)\n",
    "    Sample_Content_Without_CommsLoopsVar.append(Sample_Content_SubFile)\n",
    "    Var_Content.append(Var_SubFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Code_Struct = {}\n",
    "def CheckStruct(format_dict, syntax) :\n",
    "    Var_Index = []\n",
    "    Loop_Index = []\n",
    "    Com_Index = []\n",
    "    append_Lines_Var = False\n",
    "    append_Lines_Loop = False\n",
    "    append_Lines_Com = False\n",
    "    long_Com = False\n",
    "    stop_LC = \"None\"\n",
    "    #print(sample_files[syntax])\n",
    "    Sample_ContentsBis = sample_contents[syntax].splitlines(True)\n",
    "    for index in range(len(Sample_ContentsBis)) :\n",
    "        for exc in format_dict['var'] :\n",
    "            if(exc in Sample_ContentsBis[index]) :\n",
    "                append_Lines_Var = True\n",
    "        for exc in format_dict['loop'] :\n",
    "            if(exc in Sample_ContentsBis[index]) :\n",
    "                append_Lines_Loop = True\n",
    "                \n",
    "        for exc in format_dict['com'] :\n",
    "            if(exc in Sample_ContentsBis[index]) :\n",
    "                append_Lines_Com = True\n",
    "                \n",
    "        if(Sample_ContentsBis[index] == stop_LC) :\n",
    "            long_Com = False\n",
    "            append_Lines_Com = True\n",
    "            \n",
    "        if(long_Com == True):\n",
    "            append_Lines_Com = True\n",
    "            \n",
    "        for exc in format_dict['extended_com'] :\n",
    "            if(exc in Sample_ContentsBis[index]) :\n",
    "                append_Lines_Com = True\n",
    "                long_Com = True\n",
    "                if(exc==\"/*\"):\n",
    "                    stop_LC = \"*/\"\n",
    "                    \n",
    "        if(append_Lines_Var) :\n",
    "            Var_Index.append(str(index))\n",
    "            append_Lines_Var = False \n",
    "        if(append_Lines_Loop) :\n",
    "            Loop_Index.append(str(index))\n",
    "            append_Lines_Loop = False\n",
    "        if(append_Lines_Com and long_Com == False) : \n",
    "            Com_Index.append(str(index))\n",
    "            append_Lines_Com = False\n",
    "        elif(append_Lines_Com and long_Com ==True) : \n",
    "            Com_Index.append(str(index))\n",
    "            append_Lines_Com = False\n",
    "            \n",
    "    Code_Struct[sample_files[syntax]] = {\"VAR\": Var_Index, \"LOOP\" : Loop_Index, \"COM\": Com_Index}\n",
    "    #print(Code_Struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for index in range(len(sample_files)) :\n",
    "        increment_text = False\n",
    "        temp_text = \"\"\n",
    "        for j in range(len(sample_files[index])) :\n",
    "            if(increment_text) :\n",
    "                temp_text += (sample_files[index][j]).upper()\n",
    "            if(sample_files[index][j] == \".\") :\n",
    "                increment_text = True\n",
    "        format_dict = jsd.decodeFormat(temp_text)\n",
    "        PurgeCommentary(format_dict['com'],format_dict['extended_com'],index)\n",
    "        PurgeLoops(format_dict['loop'],index)\n",
    "        PurgeVariables(format_dict['var'],index)\n",
    "        CheckStruct(format_dict, index)\n",
    "    \n",
    "        #print(Sample_Content_Without_CommsLoopsVar)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['#d sdqsd\\n'], [], []], [[], [], ['fruits = [\"apple\", \"banana\", \"cherry\"]\\n']], [[], [], ['for x in fruits:\\n', '  print(x)']]]\n"
     ]
    }
   ],
   "source": [
    "All_Content = []\n",
    "All_Content_Name = []\n",
    "\n",
    "\n",
    "#print(\"Commentary Content : \\n\")\n",
    "#print(Commentary_Content)\n",
    "#print(\"\\nLoop Content : \\n\")\n",
    "#print(Loop_Content)\n",
    "#print(\"\\nVar Content : \\n\")\n",
    "#print(Var_Content)\n",
    "\n",
    "All_Content.append(Commentary_Content)\n",
    "All_Content.append(Var_Content)\n",
    "All_Content.append(Loop_Content)\n",
    "\n",
    "All_Content_Name.append(\"Commentary\")\n",
    "All_Content_Name.append(\"Loop\")\n",
    "All_Content_Name.append(\"Var\")\n",
    "\n",
    "print(All_Content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize = lambda Text: TfidfVectorizer().fit_transform(Text).toarray()\n",
    "\n",
    "def vectorize(Text) :\n",
    "    return TfidfVectorizer(analyzer=\"char\").fit_transform(Text).toarray()\n",
    "\n",
    "# similarity = lambda doc1, doc2: cosine_similarity([doc1, doc2])\n",
    "\n",
    "def similarity(doc1,doc2) :\n",
    "    return cosine_similarity([doc1,doc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_plagiarism(TestFiles):\n",
    "    vectors = vectorize(TestFiles)\n",
    "    s_vectors = list(zip(sample_files, vectors))\n",
    "    results = set()\n",
    "    for sample_a, text_vector_a in s_vectors:\n",
    "        new_vectors = s_vectors.copy()\n",
    "        current_index = new_vectors.index((sample_a, text_vector_a))\n",
    "        del new_vectors[current_index]\n",
    "        for sample_b, text_vector_b in new_vectors:\n",
    "            sim_score = similarity(text_vector_a, text_vector_b)[0][1]\n",
    "            sample_pair = sorted((sample_a, sample_b))\n",
    "            score = sample_pair[0], sample_pair[1], sim_score\n",
    "            results.add(score)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExecutePlagiarismChecker(ArrayToTest):\n",
    "    for array_index in range(len(ArrayToTest)):\n",
    "        temp_text = \"\"\n",
    "        for item_index in range(len(ArrayToTest[array_index])):\n",
    "            temp_text += ArrayToTest[array_index][item_index]\n",
    "        ArrayToTest[array_index] = temp_text\n",
    "    return check_plagiarism(ArrayToTest)\n",
    "scoring_Dict = {}\n",
    "\n",
    "PreJson = {}\n",
    "\n",
    "for i in range(len(sample_files)):\n",
    "    PreJson[sample_files[i]] = {}\n",
    "    for j in range(len(sample_files)):\n",
    "        if (i != j):\n",
    "            PreJson[sample_files[i]][sample_files[j]] = {}\n",
    "\n",
    "for index in range(len(All_Content)) :  \n",
    "    for score in ExecutePlagiarismChecker(All_Content[index]) :\n",
    "        result = (','.join(map(str,(score)))).split(',')\n",
    "        if index == 0 :\n",
    "            PreJson[result[0]][result[1]][\"Commentary\"] = result[2]\n",
    "            PreJson[result[1]][result[0]][\"Commentary\"] = result[2]\n",
    "        elif index == 1 : \n",
    "            PreJson[result[0]][result[1]][\"Loop\"] = result[2]\n",
    "            PreJson[result[1]][result[0]][\"Loop\"] = result[2]\n",
    "        else : \n",
    "            PreJson[result[0]][result[1]][\"Var\"] = result[2]\n",
    "            PreJson[result[1]][result[0]][\"Var\"] = result[2]\n",
    "\n",
    "for index in range(len(sample_contents)):\n",
    "   for index2 in range(len(sample_contents)):\n",
    "        if (index  != index2):\n",
    "            testPlagiat = ExecutePlagiarismChecker([sample_contents[index], sample_contents[index2]])\n",
    "            mapTestPlagiat = (','.join(map(str,(testPlagiat)))).split(',')\n",
    "            score = mapTestPlagiat[2]\n",
    "            score = score.replace(')', \"\")\n",
    "            PreJson[sample_files[index]][sample_files[index2]][\"Score\"] = score\n",
    "            PreJson[sample_files[index2]][sample_files[index]][\"Score\"] = score\n",
    "\n",
    "jsonString = json.dumps(PreJson)\n",
    "jsonFile = open(\"data.json\", \"w\")\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
