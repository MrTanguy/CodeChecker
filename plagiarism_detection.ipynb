{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['var x = math.floor(math.random() * 5);\\nbeed = 2\\nvar kek = \"kek\";\\n\\nxD LA VIE\\n\\nif(x==1) {\\n    b = 3\\n} else {\\n    b = 1\\n}\\n\\n\\n// DDDDDDDDDDDDdd\\n/* HEHEBOY \\n\\n\\n\\nSDqsd\\n*/', 'Content3\\nbeed = 5\\n// Normal Commentary', 'yes\\n// Normal Commentary', 'HEHE\\n\\n// C Normal Commentary \\n\\n/*\\nC High Commentary\\n*/']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from numpy import vectorize \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json_decoder as jsd\n",
    "import plotly.graph_objects as go\n",
    "import string\n",
    "\n",
    "s=\"\"\n",
    "sample_files = []\n",
    "load_dotenv()\n",
    "\n",
    "Space_Cleared_Exts = os.environ[\"EXTENSIONS\"].replace(\" \", \"\")\n",
    "# ------------------------------------------------------------------\n",
    "# Parcourt tout les fichiers finissant avec les extensions dans .env\n",
    "# ------------------------------------------------------------------\n",
    "for ext in os.environ[\"EXTENSIONS\"] :\n",
    "    if(ext==\",\") :\n",
    "        ext=\"[\"\n",
    "        for doc in os.listdir(\"./FilesToTest/\") :\n",
    "            if doc.endswith(str(s)) :\n",
    "                sample_files.append(''.join(doc))\n",
    "        s = \"\"\n",
    "    if(ext!=\"[\" and ext!=\"]\") :\n",
    "        s+=ext\n",
    "for doc in os.listdir(\"./FilesToTest/\") :\n",
    "    if doc.endswith(str(s.replace(\" \",\"\"))) :\n",
    "        sample_files.append(''.join(doc))\n",
    " \n",
    "sample_contents = [open(\"./FilesToTest/\"+File).read() for File in sample_files]\n",
    "print(sample_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Commentary_Content = []\n",
    "Var_Content = []\n",
    "Equal_Content = []\n",
    "Loop_Content = []\n",
    "\n",
    "Sample_Content_Double = []\n",
    "Sample_Content_Without_CommsLoops = []\n",
    "Sample_Content_Without_CommsLoopsVar = []\n",
    "# ---------------------------------------------------------------------------------\n",
    "# Parcourt notre texte et enleve les commentaires si le texte vient d'un fichier JS\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "def PurgeCommentary(com_format,ext_com_format, syntax) :\n",
    "    Sample_ContentsBis = sample_contents[syntax].splitlines(True)\n",
    "    Sample_Content_SubFile = []\n",
    "    Commentary_SubFile = []\n",
    "    Long_Comment = False\n",
    "    Append_Lines = False    \n",
    "    Stop_Ext_Com = \"None\"\n",
    "    \n",
    "    for lines in Sample_ContentsBis :\n",
    "        for syntax in com_format :\n",
    "            for ext in ext_com_format :\n",
    "                if(Stop_Ext_Com in lines):\n",
    "                    Long_Comment = False\n",
    "                    Append_Lines = True\n",
    "                if(Long_Comment) :\n",
    "                    Append_Lines = True\n",
    "                if(syntax in lines) :\n",
    "                    Append_Lines = True\n",
    "                if(ext in lines):\n",
    "                    Append_Lines = True\n",
    "                    Long_Comment = True\n",
    "                    if(ext==\"/*\") :\n",
    "                        Stop_Ext_Com = \"*/\"\n",
    "        if(Append_Lines == False and Stop_Ext_Com not in lines and Long_Comment == False):\n",
    "            Sample_Content_SubFile.append(lines)\n",
    "        if(Append_Lines and Long_Comment == False) :\n",
    "            Commentary_SubFile.append(lines)\n",
    "            Append_Lines = False\n",
    "        elif(Append_Lines and Long_Comment) :\n",
    "            Commentary_SubFile.append(lines)\n",
    "    Sample_Content_Double.append(Sample_Content_SubFile)\n",
    "    Commentary_Content.append(Commentary_SubFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PurgeLoops(format, index) :\n",
    "    Sample_Content_SubFile = []\n",
    "    Loop_SubFile = []\n",
    "    IsLoop = False\n",
    "    Append_Lines = False\n",
    "    Stop_Loop_Text = \"None\"\n",
    "    for lines in Sample_Content_Double[index] :\n",
    "        for syntax in format :\n",
    "            if(Stop_Loop_Text in lines) :\n",
    "                Append_Lines = True\n",
    "                IsLoop = False\n",
    "            if(IsLoop) :\n",
    "                Append_Lines = True\n",
    "            if(syntax in lines) :\n",
    "                Append_Lines = True\n",
    "                IsLoop = True\n",
    "                if(syntax==\"{\") :\n",
    "                    Stop_Loop_Text = \"}\"\n",
    "        if(Append_Lines == False and Stop_Loop_Text not in lines and IsLoop == False):\n",
    "            Sample_Content_SubFile.append(lines)\n",
    "        if(Append_Lines and IsLoop == False) :\n",
    "            Loop_SubFile.append(lines)\n",
    "            Append_Lines = False\n",
    "        elif(Append_Lines and IsLoop) :\n",
    "            Loop_SubFile.append(lines)\n",
    "    Sample_Content_Without_CommsLoops.append(Sample_Content_SubFile)\n",
    "    Loop_Content.append(Loop_SubFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PurgeVariables(format, index) :\n",
    "    Sample_Content_SubFile = []\n",
    "    Var_SubFile = []\n",
    "    Append_Lines = False\n",
    "    for lines in Sample_Content_Without_CommsLoops[index] :\n",
    "        for syntax in format : \n",
    "            if(syntax in lines) :\n",
    "                Append_Lines = True\n",
    "        if(Append_Lines) :\n",
    "            Var_SubFile.append(lines)\n",
    "            Append_Lines = False\n",
    "        else :\n",
    "                Sample_Content_SubFile.append(lines)\n",
    "    Sample_Content_Without_CommsLoopsVar.append(Sample_Content_SubFile)\n",
    "    Var_Content.append(Var_SubFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\\n', 'xD LA VIE\\n', '\\n', '\\n', '\\n'], ['Content3\\n'], ['yes\\n'], ['HEHE\\n', '\\n', '\\n']]\n"
     ]
    }
   ],
   "source": [
    "    for index in range(len(sample_files)) :\n",
    "        increment_text = False\n",
    "        temp_text = \"\"\n",
    "        for j in range(len(sample_files[index])) :\n",
    "            if(increment_text) :\n",
    "                temp_text += (sample_files[index][j]).upper()\n",
    "            if(sample_files[index][j] == \".\") :\n",
    "                increment_text = True\n",
    "        format_dict = jsd.decodeFormat(temp_text)\n",
    "\n",
    "        PurgeCommentary(format_dict['com'],format_dict['extended_com'],index)\n",
    "        PurgeLoops(format_dict['loop'],index)\n",
    "        PurgeVariables(format_dict['var'],index)\n",
    "    print(Sample_Content_Without_CommsLoopsVar)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commentary Content : \n",
      "\n",
      "[['// DDDDDDDDDDDDdd\\n', '/* HEHEBOY \\n', '\\n', '\\n', '\\n', 'SDqsd\\n', '*/'], ['// Normal Commentary'], ['// Normal Commentary'], ['// C Normal Commentary \\n', '/*\\n', 'C High Commentary\\n', '*/']]\n",
      "\n",
      "Loop Content : \n",
      "\n",
      "[['if(x==1) {\\n', '    b = 3\\n', '} else {\\n', '    b = 1\\n', '}\\n'], [], [], []]\n",
      "\n",
      "Var Content : \n",
      "\n",
      "[['var x = math.floor(math.random() * 5);\\n', 'beed = 2\\n', 'var kek = \"kek\";\\n'], ['beed = 5\\n'], [], []]\n"
     ]
    }
   ],
   "source": [
    "All_Content = []\n",
    "All_Content_Name = []\n",
    "\n",
    "\n",
    "print(\"Commentary Content : \\n\")\n",
    "print(Commentary_Content)\n",
    "print(\"\\nLoop Content : \\n\")\n",
    "print(Loop_Content)\n",
    "print(\"\\nVar Content : \\n\")\n",
    "print(Var_Content)\n",
    "\n",
    "All_Content.append(Commentary_Content)\n",
    "All_Content.append(Var_Content)\n",
    "All_Content.append(Loop_Content)\n",
    "\n",
    "All_Content_Name.append(\"Commentary\")\n",
    "All_Content_Name.append(\"Loop\")\n",
    "All_Content_Name.append(\"Var\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize() :\n",
    "    return \"\"\n",
    "tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize = lambda Text: TfidfVectorizer().fit_transform(Text).toarray()\n",
    "\n",
    "def vectorize(Text) :\n",
    "    return TfidfVectorizer(analyzer=\"char\").fit_transform(Text).toarray()\n",
    "\n",
    "# similarity = lambda doc1, doc2: cosine_similarity([doc1, doc2])\n",
    "\n",
    "def similarity(doc1,doc2) :\n",
    "    return cosine_similarity([doc1,doc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_plagiarism(TestFiles):\n",
    "    vectors = vectorize(TestFiles)\n",
    "    s_vectors = list(zip(sample_files, vectors))\n",
    "    results = set()\n",
    "    for sample_a, text_vector_a in s_vectors:\n",
    "        new_vectors = s_vectors.copy()\n",
    "        current_index = new_vectors.index((sample_a, text_vector_a))\n",
    "        del new_vectors[current_index]\n",
    "        for sample_b, text_vector_b in new_vectors:\n",
    "            sim_score = similarity(text_vector_a, text_vector_b)[0][1]\n",
    "            sample_pair = sorted((sample_a, sample_b))\n",
    "            score = sample_pair[0], sample_pair[1], sim_score\n",
    "            results.add(score)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[97m\n",
      "Commentary :\n",
      "\u001b[31m('carabistouille.c', 'testingfile.js', 0.8715073686353488)\n",
      "\u001b[97m['// DDDDDDDDDDDDdd\\n/* HEHEBOY \\n\\n\\n\\nSDqsd\\n*/', '// Normal Commentary', '// Normal Commentary', '// C Normal Commentary \\n/*\\nC High Commentary\\n*/']\n",
      "\u001b[32m('no.js', 'testingfile.js', 0.08419205479808882)\n",
      "\u001b[31m('carabistouille.c', 'yes.js', 0.8715073686353488)\n",
      "\u001b[97m['// DDDDDDDDDDDDdd\\n/* HEHEBOY \\n\\n\\n\\nSDqsd\\n*/', '// Normal Commentary', '// Normal Commentary', '// C Normal Commentary \\n/*\\nC High Commentary\\n*/']\n",
      "\u001b[31m('testingfile.js', 'yes.js', 1.0)\n",
      "\u001b[97m['// DDDDDDDDDDDDdd\\n/* HEHEBOY \\n\\n\\n\\nSDqsd\\n*/', '// Normal Commentary', '// Normal Commentary', '// C Normal Commentary \\n/*\\nC High Commentary\\n*/']\n",
      "\u001b[32m('no.js', 'yes.js', 0.08419205479808882)\n",
      "\u001b[32m('carabistouille.c', 'no.js', 0.15099875184329706)\n",
      "\u001b[97m\n",
      "Loop :\n",
      "\u001b[32m('no.js', 'yes.js', 0.0)\n",
      "\u001b[32m('testingfile.js', 'yes.js', 0.0)\n",
      "\u001b[32m('carabistouille.c', 'testingfile.js', 0.0)\n",
      "\u001b[32m('no.js', 'testingfile.js', 0.5875230680947945)\n",
      "\u001b[32m('carabistouille.c', 'no.js', 0.0)\n",
      "\u001b[32m('carabistouille.c', 'yes.js', 0.0)\n",
      "\u001b[97m\n",
      "Var :\n",
      "\u001b[32m('no.js', 'yes.js', 0.0)\n",
      "\u001b[32m('testingfile.js', 'yes.js', 0.0)\n",
      "\u001b[32m('carabistouille.c', 'testingfile.js', 0.0)\n",
      "\u001b[32m('carabistouille.c', 'no.js', 0.0)\n",
      "\u001b[32m('no.js', 'testingfile.js', 0.0)\n",
      "\u001b[32m('carabistouille.c', 'yes.js', 0.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sty import fg\n",
    "\n",
    "def ExecutePlagiarismChecker(ArrayToTest):\n",
    "    for array_index in range(len(ArrayToTest)):\n",
    "        temp_text = \"\"\n",
    "        for item_index in range(len(ArrayToTest[array_index])):\n",
    "            temp_text += ArrayToTest[array_index][item_index]\n",
    "        ArrayToTest[array_index] = temp_text\n",
    "    return check_plagiarism(ArrayToTest)\n",
    "Scoring = 0\n",
    "\n",
    "for index in range(len(All_Content)) : \n",
    "    print(fg.white+\"\\n\"+All_Content_Name[index]+\" :\")  \n",
    "    for score in ExecutePlagiarismChecker(All_Content[index]) :\n",
    "        result = (','.join(map(str,(score)))).split(',')\n",
    "        if(float(result[2])>=0.6) :\n",
    "            color = fg.red\n",
    "        else :\n",
    "            color = fg.green\n",
    "        print(color+str(score))\n",
    "        if(float(result[2])>=0.6) :\n",
    "            print(fg.white+str(All_Content[index]))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
